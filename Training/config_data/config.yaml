diffusion:
  timesteps: 1000
  schedule_name: cosine
  enforce_zero_terminal_snr: true
  schedule_params:
    beta_start: 0.0001
    beta_end: 0.02
    cosine_s: 0.008
  timestep_respacing: null
  mean_type: VELOCITY    
  var_type: LEARNED_RANGE  # WAS: FIXED_SMALL
  loss_type: MSE
  verbose: false

optimizer:
  lr: 0.00001
  type: bkh_pytorch_utils.Lion

validation:
  classifier_cond_scale: 4
  protocol: DDIM100  # TODO: DDPM?
  log_original: true
  log_concat: true
  log_cls_indices: -1

model:
  input_size: 256
  dims: 2
  attention_resolutions: [8, 16, 32]
  channel_mult: [0.5, 1, 1, 2, 2, 4, 4]
  dropout: 0.0
  in_channels: 2
  out_channels: 2 # WAS: 1 IF USING FIXED_SMALL
  model_channels: 128
  num_head_channels: -1 
  num_heads: 4
  num_heads_upsample: -1
  num_res_blocks: [2, 2, 2, 2, 2, 2, 2]
  resblock_updown: true
  use_checkpoint: false
  use_new_attention_order: false
  use_scale_shift_norm: true
  scale_skip_connection: false

  # conditions
  num_classes: 0
  concat_channels: 1
  guidance_drop_prob: 0.1
  missing_class_value: null
