{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "In this first phase we are focusing on getting only the High Resolutions images for the patients that respect the neccessary quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting only high resolution MRI by checking:\n",
    "- SliceThickness\n",
    "- ImageOrientationPatientDICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sagittal_slices(input_dir, output_dir):\n",
    "    json_files = glob.glob(f'{input_dir}/**/*.json', recursive=True)\n",
    "\n",
    "    des = output_dir\n",
    "    os.makedirs(des, exist_ok=True)\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if 'SliceThickness' in data and data['SliceThickness'] <= 1.5:\n",
    "                if 'ImageOrientationPatientDICOM' in data and data['ImageOrientationPatientDICOM'][1] > 0.9 and abs(data['ImageOrientationPatientDICOM'][5]) > 0.9:\n",
    "                    \n",
    "                    nii_file = json_file.replace('.json', '.nii.gz')\n",
    "                    \n",
    "                    os.system(f\"cp '{json_file}' {des}\")\n",
    "                    os.system(f\"cp '{nii_file}' {des}\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {json_file}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/scratch/Costanza/ADNI_DDPM_NIfTI'\n",
    "output_dir = '/scratch/Costanza/ADNI_DDPM_Sagittal'\n",
    "get_sagittal_slices(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extration of the patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_id(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    patient_id = base_name.split('_')[2]\n",
    "    return patient_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only the paired patients by checking:\n",
    "\n",
    "- Total Number of patients\n",
    "- Patients with both Magnetic Field Strength (1.5T and 3T) for same Series Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of patients in this dataset directory /scratch/Costanza/ADNI_DDPM_Sagittal is 99\n",
      "Number of patients with both 3T and 1.5T scans for the same SeriesDescription: 44\n",
      "Number of patients with only 3T scans: 53\n",
      "Number of patients with only 1.5T scans: 2\n",
      "Number of patients without both 3T and 1.5T scans for the same SeriesDescription: 0\n"
     ]
    }
   ],
   "source": [
    "def find_all_patients(input_dir):\n",
    "    json_files = glob.glob(f'{input_dir}/**/*.json', recursive=True)\n",
    "    all_patients = {}\n",
    "\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            patient_id = extract_patient_id(json_file)\n",
    "            series_description = data.get('SeriesDescription', 'Unknown')\n",
    "\n",
    "            # Initialize the patient's entry if not already in the dictionary\n",
    "            if patient_id not in all_patients:\n",
    "                all_patients[patient_id] = {}\n",
    "\n",
    "            if series_description not in all_patients[patient_id]:\n",
    "                all_patients[patient_id][series_description] = {'3T': False, '1.5T': False}\n",
    "\n",
    "            if 'MagneticFieldStrength' in data:\n",
    "                if data['MagneticFieldStrength'] == 3.0:\n",
    "                    all_patients[patient_id][series_description]['3T'] = True\n",
    "                elif data['MagneticFieldStrength'] == 1.5:\n",
    "                    all_patients[patient_id][series_description]['1.5T'] = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "\n",
    "    return all_patients\n",
    "\n",
    "input_dir = '/scratch/Costanza/ADNI_DDPM_Sagittal'\n",
    "all_patients = find_all_patients(input_dir)\n",
    "\n",
    "# Count patients who have both 1.5T and 3T scans for the same SeriesDescription\n",
    "patients_with_both = 0\n",
    "patients_with_3T_only = 0\n",
    "patients_with_1_5T_only = 0\n",
    "\n",
    "for patient_id, series_dict in all_patients.items():\n",
    "    has_both = any(info['3T'] and info['1.5T'] for info in series_dict.values())\n",
    "    has_3T_only = any(info['3T'] and not info['1.5T'] for info in series_dict.values())\n",
    "    has_1_5T_only = any(info['1.5T'] and not info['3T'] for info in series_dict.values())\n",
    "    \n",
    "    if has_both:\n",
    "        patients_with_both += 1\n",
    "    elif has_3T_only:\n",
    "        patients_with_3T_only += 1\n",
    "    elif has_1_5T_only:\n",
    "        patients_with_1_5T_only += 1\n",
    "\n",
    "total_patients = len(all_patients)\n",
    "patients_without_both = total_patients - (patients_with_both + patients_with_3T_only + patients_with_1_5T_only)\n",
    "\n",
    "print(f'The total number of patients in this dataset directory {input_dir} is {total_patients}')\n",
    "print(f'Number of patients with both 3T and 1.5T scans for the same SeriesDescription: {patients_with_both}')\n",
    "print(f'Number of patients with only 3T scans: {patients_with_3T_only}')\n",
    "print(f'Number of patients with only 1.5T scans: {patients_with_1_5T_only}')\n",
    "print(f'Number of patients without both 3T and 1.5T scans for the same SeriesDescription: {patients_without_both}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of SeriesDescriptions available for patient that have both 1.5T and 3T MagneticFieldStrength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesDescription</th>\n",
       "      <th>PatientCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPRAGE</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPRAGE Repeat</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MP-RAGE REPEAT</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MP-RAGE</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MPRAGE REPEAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SeriesDescription  PatientCount\n",
       "0            MPRAGE            33\n",
       "1     MPRAGE Repeat            13\n",
       "2    MP-RAGE REPEAT            11\n",
       "3           MP-RAGE            10\n",
       "4     MPRAGE REPEAT             1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/scratch/Costanza/Check/MFS&SD_sagittal_check.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "filtered_df = df.groupby(['PatientID', 'SeriesDescription'])['MagneticFieldStrength'].apply(lambda x: set(x) == {1.5, 3.0}).reset_index()\n",
    "\n",
    "filtered_df = filtered_df[filtered_df['MagneticFieldStrength']]\n",
    "\n",
    "count_series_description = filtered_df['SeriesDescription'].value_counts().reset_index()\n",
    "count_series_description.columns = ['SeriesDescription', 'PatientCount']\n",
    "\n",
    "total_patient = count_series_description['PatientCount'].sum()\n",
    "\n",
    "count_series_description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total of the column Patient Count is 68, but there are only 44 unique patients in the CSV file, it indicates that some patients have multiple series descriptions associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that clean the dataset and get just the patients that we need. From 99 we found just 44 patients with the characteristics that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique patients with both 1.5T and 3T scans with common series descriptions: 44\n"
     ]
    }
   ],
   "source": [
    "def get_patients(input_dir, output_dir):\n",
    "    json_files = glob.glob(f'{input_dir}/**/*.json', recursive=True)\n",
    "    \n",
    "    patient_scans = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if 'MagneticFieldStrength' in data and 'SeriesDescription' in data:\n",
    "                patient_id = extract_patient_id(json_file)\n",
    "                field_strength = data['MagneticFieldStrength']\n",
    "                series_description = data['SeriesDescription']\n",
    "                patient_scans[patient_id][field_strength].append((series_description, json_file))\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {json_file}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "    \n",
    "    patients_with_both = {\n",
    "        patient: field_strengths \n",
    "        for patient, field_strengths in patient_scans.items() \n",
    "        if 1.5 in field_strengths and 3.0 in field_strengths\n",
    "    }\n",
    "\n",
    "    filtered_patients = {}\n",
    "    for patient, field_strengths in patients_with_both.items():\n",
    "        series_descriptions_1_5 = set(desc for desc, _ in field_strengths[1.5])\n",
    "        series_descriptions_3_0 = set(desc for desc, _ in field_strengths[3.0])\n",
    "        common_series_descriptions = series_descriptions_1_5.intersection(series_descriptions_3_0)\n",
    "        \n",
    "        if common_series_descriptions:\n",
    "            filtered_patients[patient] = field_strengths\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for patient, field_strengths in filtered_patients.items():\n",
    "        series_descriptions_1_5 = {desc: file for desc, file in field_strengths[1.5]}\n",
    "        series_descriptions_3_0 = {desc: file for desc, file in field_strengths[3.0]}\n",
    "        common_series_descriptions = set(series_descriptions_1_5.keys()).intersection(series_descriptions_3_0.keys())\n",
    "        \n",
    "        for series_description in common_series_descriptions:\n",
    "            json_file_1_5 = series_descriptions_1_5[series_description]\n",
    "            json_file_3_0 = series_descriptions_3_0[series_description]\n",
    "            \n",
    "            image_file_1_5 = json_file_1_5.replace('.json', '.nii.gz') \n",
    "            image_file_3_0 = json_file_3_0.replace('.json', '.nii.gz')\n",
    "            \n",
    "            patient_output_dir = os.path.join(output_dir, patient)\n",
    "            if not os.path.exists(patient_output_dir):\n",
    "                os.makedirs(patient_output_dir)\n",
    "            \n",
    "            json_file_1_5_new = os.path.join(patient_output_dir, f'{os.path.basename(json_file_1_5).replace(\".json\", \"\")}_1.5T.json')\n",
    "            image_file_1_5_new = os.path.join(patient_output_dir, f'{os.path.basename(image_file_1_5).replace(\".nii.gz\", \"\")}_1.5T.nii.gz')\n",
    "            json_file_3_0_new = os.path.join(patient_output_dir, f'{os.path.basename(json_file_3_0).replace(\".json\", \"\")}_3.0T.json')\n",
    "            image_file_3_0_new = os.path.join(patient_output_dir, f'{os.path.basename(image_file_3_0).replace(\".nii.gz\", \"\")}_3.0T.nii.gz')\n",
    "            \n",
    "            shutil.copy(json_file_1_5, json_file_1_5_new)\n",
    "            shutil.copy(image_file_1_5, image_file_1_5_new)\n",
    "            shutil.copy(json_file_3_0, json_file_3_0_new)\n",
    "            shutil.copy(image_file_3_0, image_file_3_0_new)\n",
    "    \n",
    "    num_patients = len(filtered_patients)\n",
    "    return num_patients\n",
    "\n",
    "input_dir = '/scratch/Costanza/ADNI_DDPM_Sagittal'\n",
    "output_dir = '/scratch/Costanza/ADNI_DDPM_S_Clean'\n",
    "num_patients = get_patients(input_dir, output_dir)\n",
    "print(f\"Number of unique patients with both 1.5T and 3T scans with common series descriptions: {num_patients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1169 has 2 pairs\n",
      "Patient 1276 has 2 pairs\n",
      "Patient 1241 has 2 pairs\n",
      "Patient 0622 has 2 pairs\n",
      "Patient 0058 has 2 pairs\n",
      "Patient 0602 has 2 pairs\n",
      "Patient 1251 has 2 pairs\n",
      "Patient 1267 has 2 pairs\n",
      "Patient 1206 has 2 pairs\n",
      "Patient 0031 has 2 pairs\n",
      "Patient 1288 has 2 pairs\n",
      "Patient 0926 has 2 pairs\n",
      "Patient 1190 has 2 pairs\n",
      "Patient 1256 has 2 pairs\n",
      "Patient 0605 has 2 pairs\n",
      "Patient 0677 has 2 pairs\n",
      "Patient 0061 has 2 pairs\n",
      "Patient 0260 has 2 pairs\n",
      "Patient 0479 has 2 pairs\n",
      "Patient 0963 has 2 pairs\n",
      "Patient 1035 has 2 pairs\n",
      "Patient 1123 has 2 pairs\n",
      "Patient 0553 has 2 pairs\n",
      "Patient 1250 has 2 pairs\n",
      "Total patients with complete pairs: 44\n",
      "Total patients with multiple pairs: 24\n",
      "Total patients checked: 44\n"
     ]
    }
   ],
   "source": [
    "def check_patient_folder(patient_folder):\n",
    "    nii_files = glob.glob(os.path.join(patient_folder, '*.nii.gz'))\n",
    "\n",
    "    image_3T_files = []\n",
    "    image_1_5T_files = []\n",
    "\n",
    "    for nii_file in nii_files:\n",
    "        if '3.0T' in nii_file:\n",
    "            image_3T_files.append(nii_file)\n",
    "        elif '1.5T' in nii_file:\n",
    "            image_1_5T_files.append(nii_file)\n",
    "\n",
    "    num_pairs = min(len(image_3T_files), len(image_1_5T_files))\n",
    "\n",
    "    if not image_3T_files:\n",
    "        print(f\"No 3.0T images found in {patient_folder}\")\n",
    "    if not image_1_5T_files:\n",
    "        print(f\"No 1.5T images found in {patient_folder}\")\n",
    "\n",
    "    return num_pairs, image_1_5T_files, image_3T_files\n",
    "\n",
    "def check_all_patient_folders(input_dir):\n",
    "    patient_folders = [f.path for f in os.scandir(input_dir) if f.is_dir()]\n",
    "    complete_pairs_count = 0\n",
    "    multiple_pairs_count = 0\n",
    "    for patient_folder in patient_folders:\n",
    "        num_pairs, _, _ = check_patient_folder(patient_folder)\n",
    "        if num_pairs > 0:\n",
    "            complete_pairs_count += 1\n",
    "            if num_pairs > 1:\n",
    "                multiple_pairs_count += 1\n",
    "                print(f\"Patient {os.path.basename(patient_folder)} has {num_pairs} pairs\")\n",
    "        else:\n",
    "            print(f\"Incomplete pairs in {patient_folder}\")\n",
    "\n",
    "    print(f\"Total patients with complete pairs: {complete_pairs_count}\")\n",
    "    print(f\"Total patients with multiple pairs: {multiple_pairs_count}\")\n",
    "    print(f\"Total patients checked: {len(patient_folders)}\")\n",
    "    \n",
    "input_dir = '/scratch/Costanza/ADNI_DDPM_S_Clean'\n",
    "check_all_patient_folders(input_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As last step we are going to clean the dataset from unnecessary pairs of 1.5T and 3.0, remaning just with one couple of pair for patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_pairs_folder(input_dir, output_dir):\n",
    "    patient_folders = [f.path for f in os.scandir(input_dir) if f.is_dir()]\n",
    "    \n",
    "    for patient_folder in patient_folders:\n",
    "        num_pairs, image_1_5T_files, image_3T_files = check_patient_folder(patient_folder)\n",
    "\n",
    "        if num_pairs > 0:\n",
    "            # Only keep the first pair\n",
    "            selected_1_5T_file = image_1_5T_files[0]\n",
    "            selected_3T_file = image_3T_files[0]\n",
    "\n",
    "            patient_id = os.path.basename(patient_folder)\n",
    "            patient_output_dir = os.path.join(output_dir, patient_id)\n",
    "            os.makedirs(patient_output_dir, exist_ok=True)\n",
    "\n",
    "            shutil.copy(selected_1_5T_file, os.path.join(patient_output_dir, os.path.basename(selected_1_5T_file)))\n",
    "            shutil.copy(selected_3T_file, os.path.join(patient_output_dir, os.path.basename(selected_3T_file)))\n",
    "\n",
    "            json_1_5T_file = selected_1_5T_file.replace('.nii.gz', '.json')\n",
    "            json_3T_file = selected_3T_file.replace('.nii.gz', '.json')\n",
    "\n",
    "            if os.path.exists(json_1_5T_file):\n",
    "                shutil.copy(json_1_5T_file, os.path.join(patient_output_dir, os.path.basename(json_1_5T_file)))\n",
    "            if os.path.exists(json_3T_file):\n",
    "                shutil.copy(json_3T_file, os.path.join(patient_output_dir, os.path.basename(json_3T_file)))\n",
    "\n",
    "input_dir = '/scratch/Costanza/ADNI_DDPM_S_Clean'\n",
    "output_dir = '/scratch/Costanza/ADNI_DDPM_S_Single_Pairs'\n",
    "create_single_pairs_folder(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HD-BET Tool\n",
    "\n",
    "To use HD-BET Skull stripping tool we need to restructure the dataset  without folder for each patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dataset_and_rename(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.nii.gz'):\n",
    "                parts = file.split('_')\n",
    "                new_parts = parts[2:]\n",
    "                if 'T' in new_parts[-1]:\n",
    "                    new_parts[-1] = new_parts[-1].replace('3.0T', '3_0T').replace('1.5T', '1_5T')\n",
    "                new_filename = '_'.join(new_parts)\n",
    "                file_path = os.path.join(root, file)\n",
    "                shutil.copy(file_path, os.path.join(output_dir, new_filename))\n",
    "\n",
    "input_dir = '/scratch/Costanza/ADNI_DDPM_S_Single_Pairs'\n",
    "output_dir = '/scratch/Costanza/ADNI_Flat'\n",
    "flatten_dataset_and_rename(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after HD-BET we will remove the mask saved by the tool because we do not need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0023_MPRAGE_20101222091037_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0311_MPRAGE_20110901102522_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0622_RMRKH062508_ADNI_14M4_TS_3_20080625123200_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0767_MPRAGE_20110903152917_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1194_MPRAGE_20110330095021_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0156_MPRAGE_20160613134720_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1288_MPRAGE_20071010152428_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0405_MN060006594_10982145_20060516102237_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0156_MPRAGE_20070215135553_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0260_ADNI_3T12M4_TS_2_20060501130654_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0416_MPRAGE_20151209120000_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0089_MPRAGE_20090202145931_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0605_ADNI_3T12M4_TS_2_20061218104201_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0031_MPRAGE_20081202074749_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0369_MPRAGE_20090716152824_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0260_RMRKH0508C_ADNI_14M4_TS_3_20070508140810_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0056_MPRAGE_20101210075051_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0602_ADNI_3T_14M4_TS_2_20090811112236_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0061_MPRAGE_Repeat_20071213125030_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0257_MPRAGE_20130820090302_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0553_ADNI_3T_14M4_TS_3_20080708125946_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1035_MPRAGE_20081118134809_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1267_8158386_ADNI_12M4TS_2_20070316110423_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1023_MPRAGE_20100113095322_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0479_MPRAGE_20120917071158_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1203_MPRAGE_20100327152009_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0173_MPRAGE_20070227074352_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0479_MPRAGE_20080529121150_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1206_8627743-1_ADNI_14M4-TS_2_20080222105309_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0058_MPRAGE_Repeat_20120402111707_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0061_MPRAGE_Repeat_20081219084621_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1206_7657961-1_ADNI_3T12M4_TS_3_20070130151841_4_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0369_MPRAGE_SENSE_20080513091903_301_real_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0173_MPRAGE_20160205115500_7_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0023_MPRAGE_20061121132034_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0089_MPRAGE_20111005161927_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0257_MPRAGE_20090812102209_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1251_4301428_ADNI_3T12M4_TS_3_20070309112815_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1195_MPRAGE_20120321131328_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0926_MPRAGE_20081021123631_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0405_ADNI_3T12M4_TS_2_20070105103910_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1123_MPRAGE_20150218135152_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1251_4448333_5621341_2_20070831131241_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0555_MPRAGE_20160601142533_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0602_3060977_ADNI_14M4_TS_2_20070808131310_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1023_MPRAGE_20130107100906_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1190_MPRAGE_Repeat_20140219170341_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1276_MPRAGE_20090331153511_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0605_MN060016661_ADNI_20061218123000_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0677_MPRAGE_20160722092331_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0553_40108398_ADNI_14M4_TS_2_20080821092606_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1267_9670033_ADNI_3T_15M3_TSa_2_20100318090102_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0677_MPRAGE_Repeat_20090727091748_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1250_5290451_ADNI_1F_2_20100525091518_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0311_MPRAGE_20071018165908_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0031_MPRAGE_20061030120256_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1241_8946373_ADNI_12M4TS_RESEARCH_2_20080508134834_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1194_MPRAGE_20070822151660_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1202_MPRAGE_20110616124907_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1250_4292258_ADNI_3T12M4_TS_3_20070228104603_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0555_MPRAGE_20121211144019_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1190_MPRAGE_Repeat_20080108095632_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1169_MPRAGE_20090121102312_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1276_MPRAGE_REPEAT_20100420142030_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1288_MPRAGE_Repeat_20080303180909_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1256_MPRAGE_Repeat_20070223110332_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0963_MPRAGE_Repeat_20091028111214_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0021_MPRAGE_20071112102853_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0058_MPRAGE_20081209115046_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0021_MPRAGE_20131017123621_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0767_MPRAGE_20131029165057_6_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1241_8796758_ADNI_3T14M4TS_2_20080306101047_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1169_MPRAGE_20120202134709_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0056_MPRAGE_20131213120542_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1256_MPRAGE_Repeat_20071011094756_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0622_RMRKH062508C_ADNI_3T_14M4_TS_2_20080625131838_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0359_MPRAGE_20160714083550_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0059_MPRAGE_20141215095159_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0359_MPRAGE_20101104104950_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1123_MPRAGE_20071106110846_4_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1195_MPRAGE_20100227151820_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0926_MPRAGE_20081021084507_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0963_MPRAGE_Repeat_20070404151543_3_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1203_MPRAGE_20110323140133_2_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0416_MPRAGE_20070502153547_2_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1035_MPRAGE_20081118124843_5_3_0T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/0059_MPRAGE_20120120093127_3_1_5T_mask.nii.gz\n",
      "Removing: /scratch/Costanza/ADNI_F_SkullStripping/1202_MPRAGE_20090217064402_2_1_5T_mask.nii.gz\n",
      "Total number of mask files removed: 88\n"
     ]
    }
   ],
   "source": [
    "def remove_mask_files(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('_mask.nii.gz'):\n",
    "                count += 1\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Removing: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "    return count\n",
    "\n",
    "directory = '/scratch/Costanza/ADNI_F_SkullStripping'\n",
    "num_files = remove_mask_files(directory)\n",
    "print(f\"Total number of mask files removed: {num_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
