{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for the additional dataset\n",
    "\n",
    "1. We extracted the necessary 3T images from a PPMI control dataset to supplement our existing dataset.\n",
    "\n",
    "2. Rician noise was applied to these 3T images to simulate lower-quality 1.5T images, creating a paired dataset. The noisy 3T images serve as the 1.5T equivalents, while the original 3T images act as the ground truth, consistent with the approach used in our initial dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import shutil\n",
    "import monai as mn\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sagittal_and_3T_slices(input_dir, output_dir):\n",
    "    json_files = glob.glob(f'{input_dir}/**/*.json', recursive=True)\n",
    "    \n",
    "    des = output_dir\n",
    "    os.makedirs(des, exist_ok=True)\n",
    "    \n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Check for 3T magnetic field strength\n",
    "            if 'MagneticFieldStrength' in data and data['MagneticFieldStrength'] == 3.0:\n",
    "                # Check for SliceThickness and ImageOrientationPatientDICOM conditions\n",
    "                if 'SliceThickness' in data and data['SliceThickness'] <= 1.5:\n",
    "                    if 'ImageOrientationPatientDICOM' in data and data['ImageOrientationPatientDICOM'][1] > 0.9 and abs(data['ImageOrientationPatientDICOM'][5]) > 0.9:\n",
    "                        \n",
    "                        nii_file = json_file.replace('.json', '.nii.gz')\n",
    "                        \n",
    "                        os.system(f\"cp '{json_file}' {des}\")\n",
    "                        os.system(f\"cp '{nii_file}' {des}\")\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {json_file}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/scratch/Data/PPMI/PPMI_Control_nifti'\n",
    "output_dir = '/scratch/Costanza/PPMI'\n",
    "get_sagittal_and_3T_slices(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patient_id(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    patient_id = base_name.split('_')[2]\n",
    "    return patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of patients in this dataset directory /scratch/Costanza/PPMI is 137\n",
      "Number of patients with 3T scans: 137\n",
      "Number of patients without 3T scans: 0\n"
     ]
    }
   ],
   "source": [
    "def find_all_patients(input_dir):\n",
    "    json_files = glob.glob(f'{input_dir}/**/*.json', recursive=True)\n",
    "    all_patients = {}\n",
    "\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            patient_id = extract_patient_id(json_file)\n",
    "            \n",
    "            # Check for 3T magnetic field strength\n",
    "            if 'MagneticFieldStrength' in data and data['MagneticFieldStrength'] == 3.0:\n",
    "                if patient_id not in all_patients:\n",
    "                    all_patients[patient_id] = True  # Indicates this patient has at least one 3T scan\n",
    "            else:\n",
    "                if patient_id not in all_patients:\n",
    "                    all_patients[patient_id] = False  # Indicates this patient does not have a 3T scan\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_file}: {e}\")\n",
    "\n",
    "    return all_patients\n",
    "\n",
    "input_dir = '/scratch/Costanza/PPMI'\n",
    "all_patients = find_all_patients(input_dir)\n",
    "\n",
    "# Count the number of patients with and without 3T scans\n",
    "total_patients = len(all_patients)\n",
    "patients_with_3T = sum(has_3T for has_3T in all_patients.values())\n",
    "patients_without_3T = total_patients - patients_with_3T\n",
    "\n",
    "print(f'The total number of patients in this dataset directory {input_dir} is {total_patients}')\n",
    "print(f'Number of patients with 3T scans: {patients_with_3T}')\n",
    "print(f'Number of patients without 3T scans: {patients_without_3T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with 1 scan: 67\n",
      "Number of patients with 2 scans: 50\n",
      "Number of patients with 3 scans: 13\n",
      "Number of patients with 4 scans: 6\n",
      "Number of patients with more than 4 scans: 1\n",
      "\n",
      "Patients with more than 4 scans:\n",
      "Patient 4085 has 7 scans.\n"
     ]
    }
   ],
   "source": [
    "def find_all_patients(input_dir):\n",
    "    nii_files = glob.glob(f'{input_dir}/**/*.nii.gz', recursive=True)\n",
    "    all_patients = defaultdict(dict)\n",
    "\n",
    "    for nii_file in nii_files:\n",
    "        try:\n",
    "            # Assuming the corresponding JSON file has the same name but with .json extension\n",
    "            json_file = nii_file.replace(\".nii.gz\", \".json\")\n",
    "            if not os.path.exists(json_file):\n",
    "                continue\n",
    "            \n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Extract patient ID and check magnetic field strength\n",
    "            patient_id = extract_patient_id(nii_file)\n",
    "            magnetic_field_strength = data.get('MagneticFieldStrength', None)\n",
    "            \n",
    "            if magnetic_field_strength == 3.0:\n",
    "                if '3T' not in all_patients[patient_id]:\n",
    "                    all_patients[patient_id]['3T'] = []\n",
    "                all_patients[patient_id]['3T'].append(nii_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {nii_file}: {e}\")\n",
    "\n",
    "    # Add the count of scans for each patient\n",
    "    scan_counts = {}\n",
    "    for patient_id in all_patients:\n",
    "        scan_count = len(all_patients[patient_id].get('3T', []))\n",
    "        scan_counts[patient_id] = scan_count\n",
    "    \n",
    "    return scan_counts\n",
    "\n",
    "def extract_patient_id(filename):\n",
    "    return os.path.basename(filename).split('_')[2]\n",
    "\n",
    "input_dir = '/scratch/Costanza/PPMI'\n",
    "scan_counts = find_all_patients(input_dir)\n",
    "\n",
    "scan_distribution = Counter(scan_counts.values())\n",
    "\n",
    "categories = {1: 0, 2: 0, 3: 0, 4: 0, 'more_than_4': 0}\n",
    "\n",
    "for count, num_patients in scan_distribution.items():\n",
    "    if count >= 5:\n",
    "        categories['more_than_4'] += num_patients\n",
    "    else:\n",
    "        categories[count] = num_patients\n",
    "\n",
    "# Print the distribution\n",
    "print(f'Number of patients with 1 scan: {categories[1]}')\n",
    "print(f'Number of patients with 2 scans: {categories[2]}')\n",
    "print(f'Number of patients with 3 scans: {categories[3]}')\n",
    "print(f'Number of patients with 4 scans: {categories[4]}')\n",
    "print(f'Number of patients with more than 4 scans: {categories[\"more_than_4\"]}')\n",
    "\n",
    "print(\"\\nPatients with more than 4 scans:\")\n",
    "for patient_id, scan_count in scan_counts.items():\n",
    "    if scan_count > 4:\n",
    "        print(f'Patient {patient_id} has {scan_count} scans.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of patients with 3T scans: 137\n",
      "Number of patients with multiple 3T scans: 70\n"
     ]
    }
   ],
   "source": [
    "def find_all_patients(input_dir):\n",
    "    nii_files = glob.glob(f'{input_dir}/**/*.nii.gz', recursive=True)\n",
    "    all_patients = defaultdict(dict)\n",
    "\n",
    "    for nii_file in nii_files:\n",
    "        try:\n",
    "            json_file = nii_file.replace(\".nii.gz\", \".json\")\n",
    "            if not os.path.exists(json_file):\n",
    "                continue\n",
    "            \n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            patient_id = extract_patient_id(nii_file)\n",
    "            magnetic_field_strength = data.get('MagneticFieldStrength', None)\n",
    "            \n",
    "            if magnetic_field_strength == 3.0:\n",
    "                if '3T' not in all_patients[patient_id]:\n",
    "                    all_patients[patient_id]['3T'] = []\n",
    "                all_patients[patient_id]['3T'].append(nii_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {nii_file}: {e}\")\n",
    "\n",
    "    return all_patients\n",
    "\n",
    "def extract_patient_id(filename):\n",
    "    return os.path.basename(filename).split('_')[2]\n",
    "\n",
    "input_dir = '/scratch/Costanza/PPMI'\n",
    "all_patients = find_all_patients(input_dir)\n",
    "\n",
    "patients_with_3T = len(all_patients)\n",
    "patients_with_multiple_3T = sum(1 for scans in all_patients.values() if len(scans['3T']) > 1)\n",
    "\n",
    "print(f'The total number of patients with 3T scans: {patients_with_3T}')\n",
    "print(f'Number of patients with multiple 3T scans: {patients_with_multiple_3T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HD-BET Tool\n",
    "\n",
    "'hd-bet -i /scratch/Costanza/PPMI -o /scratch/Costanza/PPMI_NO_SKULL'\n",
    "\n",
    "and now we remove the unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mask files removed: 0\n"
     ]
    }
   ],
   "source": [
    "def remove_mask_files(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('_mask.nii.gz'):\n",
    "                count += 1\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Removing: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "    return count\n",
    "\n",
    "directory = '/scratch/Costanza/PPMI_NO_SKULL'\n",
    "num_files = remove_mask_files(directory)\n",
    "print(f\"Total number of mask files removed: {num_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully organized.\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"/scratch/Costanza/PPMI_NO_SKULL\"\n",
    "output_dir = \"/scratch/Costanza/PPMI_SkullStripping\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".nii.gz\"):\n",
    "        patient_id = filename.split(\"_\")[2]  \n",
    "        \n",
    "        patient_dir = os.path.join(output_dir, patient_id)\n",
    "        os.makedirs(patient_dir, exist_ok=True)\n",
    "        \n",
    "        shutil.move(os.path.join(input_dir, filename), os.path.join(patient_dir, filename))\n",
    "\n",
    "print(\"Dataset successfully organized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Rician Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create a paired dataset by using the 3T as ground truth and a noisy version of it where it was added Rician Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rician_noise(image, noise_level):\n",
    "    \"\"\"\n",
    "    Adds Rician noise to a given image.\n",
    "    \n",
    "    Args:\n",
    "    - image (numpy.ndarray): The input image to which Rician noise will be added.\n",
    "    - noise_level (float): The standard deviation of the Gaussian distributions used for the noise.\n",
    "\n",
    "    Returns:\n",
    "    - noisy_image (numpy.ndarray): The image with added Rician noise.\n",
    "    \"\"\"\n",
    "    if image.max() > 1.0:\n",
    "        image = image / np.max(image)  # Normalize to [0, 1]\n",
    "    \n",
    "    rician_noise = mn.transforms.RandRicianNoise(prob=1.0, mean=0.0, std=noise_level)\n",
    "    noisy_image = rician_noise(image)\n",
    "    \n",
    "    noisy_image = (noisy_image * 255).astype(np.uint8)  # Rescale to [0, 255] if needed\n",
    "    return noisy_image\n",
    "\n",
    "def save_nii_image(image_data, reference_nii, output_path):\n",
    "    new_nii = nib.Nifti1Image(image_data, affine=reference_nii.affine, header=reference_nii.header)\n",
    "    nib.save(new_nii, output_path)\n",
    "\n",
    "def process_patient_rician_noise(dataset_dir, noise_level):\n",
    "    for patient_id in sorted(os.listdir(dataset_dir)):\n",
    "        patient_dir = os.path.join(dataset_dir, patient_id)\n",
    "        \n",
    "        if os.path.isdir(patient_dir):\n",
    "            unique_files = set()  \n",
    "            \n",
    "            for file_name in sorted(os.listdir(patient_dir)):\n",
    "                if file_name.endswith('.nii.gz'):\n",
    "                    unique_name = file_name.split('.')[0]\n",
    "                    if unique_name in unique_files:\n",
    "                        continue\n",
    "                    unique_files.add(unique_name)\n",
    "\n",
    "                    file_path = os.path.join(patient_dir, file_name)\n",
    "                    nii_image = nib.load(file_path)\n",
    "                    image_data = nii_image.get_fdata()\n",
    "\n",
    "                    noisy_image_data = add_rician_noise(image_data, noise_level=noise_level)\n",
    "                    noisy_file_name = unique_name + '_rician_noise.nii.gz'\n",
    "                    noisy_file_path = os.path.join(patient_dir, noisy_file_name)\n",
    "\n",
    "                    save_nii_image(noisy_image_data, nii_image, noisy_file_path)\n",
    "\n",
    "                    print(f\"Saved noisy image for patient {patient_id} at {noisy_file_path}\")\n",
    "                    \n",
    "dataset_dir = \"/scratch/Costanza/PPMI_SkullStripping\"\n",
    "process_patient_rician_noise(dataset_dir, noise_level=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing all the patient folders with images\n",
    "base_dir = \"/scratch/Costanza/PPMI_SkullStripping\"\n",
    "\n",
    "# Iterate over all patient folders\n",
    "for patient_folder in os.listdir(base_dir):\n",
    "    patient_dir = os.path.join(base_dir, patient_folder)\n",
    "    \n",
    "    # Iterate over all the files in the patient folder\n",
    "    for filename in os.listdir(patient_dir):\n",
    "        if filename.endswith(\"_rician_noise.nii.gz\"):\n",
    "            # Construct the full path of the file\n",
    "            noisy_img_path = os.path.join(patient_dir, filename)\n",
    "            \n",
    "            # Remove the noisy image\n",
    "            os.remove(noisy_img_path)\n",
    "\n",
    "print(\"All noisy images have been removed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
